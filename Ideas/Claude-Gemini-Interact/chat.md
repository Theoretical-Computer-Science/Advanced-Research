>*GEMINI*


To demonstrate the **Precision Polymath** approach, let us tackle a foundational problem that bridges **Classical Mechanics**, **Control Theory**, and **Software Engineering**: the stabilization of an **Inverted Pendulum on a Cart**.

This system is the “hydrogen atom” of robotics and aerospace engineering—it is inherently unstable, non-linear, and under-actuated.

-----

### 1. First Principles Derivation (Lagrangian Mechanics)

To control the system, we must first understand its dynamics. We define the state by the cart position $x$ and the pendulum angle $\theta$ (where $\theta=0$ is upright).

**Kinetic Energy ($T$):**
Sum of the cart’s energy and the pendulum’s energy (using the velocity of the pendulum’s center of mass).

$$T = \frac{1}{2}M\dot{x}^2 + \frac{1}{2}m\left( \dot{x}_p^2 + \dot{y}_p^2 \right)$$

where $x_p = x + \ell \sin\theta$ and $y_p = \ell \cos\theta$.

**Potential Energy ($V$):**

$$V = mg\ell \cos\theta$$

**The Lagrangian ($L = T - V$):**

$$L = \frac{1}{2}(M+m)\dot{x}^2 + m\ell\dot{x}\dot{\theta}\cos\theta + \frac{1}{2}m\ell^2\dot{\theta}^2 - mg\ell\cos\theta$$

Applying the Euler-Lagrange equation $\frac{d}{dt}\frac{\partial L}{\partial \dot{q}_i} - \frac{\partial L}{\partial q_i} = F_i$, we derive the non-linear equations of motion:

1. $(M+m)\ddot{x} + m\ell\ddot{\theta}\cos\theta - m\ell\dot{\theta}^2\sin\theta = F$
1. $m\ell^2\ddot{\theta} + m\ell\ddot{x}\cos\theta - mg\ell\sin\theta = 0$

-----

### 2. Linearization and State-Space Representation

To design a linear controller (like LQR), we linearize around the unstable equilibrium $\theta \approx 0$. Assuming small angles ($\cos\theta \approx 1, \sin\theta \approx \theta, \dot{\theta}^2 \approx 0$):

$$\dot{\mathbf{x}} = \mathbf{Ax} + \mathbf{Bu}$$

Where the state vector is $\mathbf{x} = [x, \dot{x}, \theta, \dot{\theta}]^T$ and the matrices are:

$$\mathbf{A} = \begin{bmatrix} 0 & 1 & 0 & 0 \ 0 & \frac{-b}{M} & \frac{mg}{M} & 0 \ 0 & 0 & 0 & 1 \ 0 & \frac{-b}{M\ell} & \frac{(M+m)g}{M\ell} & 0 \end{bmatrix}, \quad \mathbf{B} = \begin{bmatrix} 0 \ \frac{1}{M} \ 0 \ \frac{1}{M\ell} \end{bmatrix}$$

-----

### 3. Optimal Control: The Linear Quadratic Regulator (LQR)

We want to find a control law $u = -K\mathbf{x}$ that minimizes the cost function $J$:

$$J = \int_{0}^{\infty} (\mathbf{x}^T \mathbf{Q} \mathbf{x} + u^T R u) dt$$

This requires solving the **Algebraic Riccati Equation (ARE)** for $\mathbf{P}$:
$$\mathbf{A}^T\mathbf{P} + \mathbf{PA} - \mathbf{PBR}^{-1}\mathbf{B}^T\mathbf{P} + \mathbf{Q} = 0$$
The optimal gain is then $K = R^{-1}\mathbf{B}^T\mathbf{P}$.

-----

### 4. Computational Implementation (Python)

Below is a production-grade simulation using `scipy` to solve the control problem and `numpy` for the dynamics.

```python
import numpy as np
from scipy.linalg import solve_continuous_are
from scipy.integrate import odeint

class InvertedPendulum:
    def __init__(self):
        # Parameters
        self.M = 0.5    # Mass of cart (kg)
        self.m = 0.2    # Mass of pendulum (kg)
        self.b = 0.1    # Friction (N/m/s)
        self.ell = 0.3  # Length to center of mass (m)
        self.g = 9.81   # Gravity (m/s^2)
        
        self.K = self._compute_lqr_gain()

    def _compute_lqr_gain(self):
        """Solve ARE to find optimal feedback gain K."""
        # Linearized A and B matrices
        p = (self.M + self.m) * self.g / (self.M * self.ell)
        A = np.array([
            [0, 1, 0, 0],
            [0, -self.b/self.M, self.m*self.g/self.M, 0],
            [0, 0, 0, 1],
            [0, -self.b/(self.M*self.ell), p, 0]
        ])
        B = np.array([[0], [1/self.M], [0], [1/(self.M*self.ell)]])
        
        # Cost matrices: penalize angle error and high control effort
        Q = np.diag([10, 1, 100, 1]) 
        R = np.array([[0.01]])
        
        P = solve_continuous_are(A, B, Q, R)
        K = np.linalg.inv(R) @ B.T @ P
        return K

    def dynamics(self, x, t):
        """Non-linear equations of motion."""
        theta = x[2]
        theta_dot = x[3]
        
        # State-feedback control u = -Kx
        # We target theta=0, x=0
        u = -self.K @ (x - np.array([0, 0, 0, 0]))
        u = u[0] # Scalar force

        # Helper terms
        sin_t = np.sin(theta)
        cos_t = np.cos(theta)
        
        # Solve for accelerations
        det = self.M + self.m * sin_t**2
        x_accel = (u + self.m*self.ell*theta_dot**2*sin_t - self.m*self.g*sin_t*cos_t) / det
        theta_accel = (-u*cos_t - self.m*self.ell*theta_dot**2*sin_t*cos_t + (self.M+self.m)*self.g*sin_t) / (self.ell * det)
        
        return [x[1], x_accel, x[3], theta_accel]

# Simulation execution
model = InvertedPendulum()
t = np.linspace(0, 5, 500)
# Initial state: 0.2m offset, 0.3 rad (approx 17 deg) tilt
x0 = [0.2, 0, 0.3, 0]

sol = odeint(model.dynamics, x0, t)

print(f"Final Angle: {sol[-1, 2]:.4f} rad (Target: 0)")
```

-----

### 5. Synthesis and Insight

- **Dimensional Integrity:** Note that the cost matrix $Q$ has dimensions that weight position ($x$) and angle ($\theta$) differently. Because an error of $1$ radian is much more critical than $1$ meter, we weight the angle penalty ($100$) more heavily.
- **The “Energy” Perspective:** In non-linear control, we could also use a **Lyapunov-based** approach (Energy Shaping). If we simply pump energy into the system until it reaches the upright position (Swing-up), and then hand off to the LQR controller derived above, we create a robust global stabilizer.
- **Real-World Application:** This exact logic governs the stabilization of the **SpaceX Falcon 9** during vertical landing (where the rocket is the inverted pendulum and the cold-gas thrusters/gimbaled engines provide the force $F$).

**How would you like to extend this?** We could explore **Kalman Filtering** to handle sensor noise, or move into **Tensor Calculus** to generalize these dynamics for multi-body robotic chains.